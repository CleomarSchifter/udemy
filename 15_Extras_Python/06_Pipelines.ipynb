{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.decomposition import PCA \n",
    "\n",
    "from sklearn.model_selection import KFold, cross_val_score, GridSearchCV, train_test_split\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "\n",
    "from matplotlib import pyplot\n",
    "import random\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from pickle import dump, load\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13230, 247)\n"
     ]
    }
   ],
   "source": [
    "# Load training dataset\n",
    "filename = 'data\\TRAIN_CLAIM_FL_ALL_GROUPED.csv'\n",
    "dataset = pd.read_csv(filename, low_memory=False)\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 7427, 1: 5803})\n"
     ]
    }
   ],
   "source": [
    "# Extract the target variable and checking the class distribution\n",
    "target = dataset['target']\n",
    "print(Counter(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13230, 235)\n",
      "                             hasMissing\n",
      "qtdclaimsprovider                  True\n",
      "qtdclaimlinesprovider              True\n",
      "qtdmemberprovider                  True\n",
      "avgticketperclaimprovider          True\n",
      "avgticketpermemberprovider         True\n",
      "avgclaimspermemberprovider         True\n",
      "avgclaimlineperclaimprovider       True\n",
      "qtdclaimsmember                    True\n",
      "qtdclaimlinesmember                True\n",
      "qtdprovidermember                  True\n",
      "avgticketperclaimmember            True\n",
      "avgticketperprovidermember         True\n",
      "avgclaimsperprovidermember         True\n",
      "avgclaimlineperclaimmember         True\n",
      "provider_age_time_of_service       True\n",
      "amount_paid                        True\n",
      "133\n",
      "Counter({0: 7333, 1: 5764})\n",
      "Index(['source', '8080'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "######################################################################################################\n",
    "#Data exploratory\n",
    "#####################################################################################################\n",
    "\n",
    "# Filter Eligibles variables for the model (we did not drop provider_id and maxdos because they are goint to be used to split data)\n",
    "collist = dataset.columns.tolist()\n",
    "columnsToDrop = np.array(['claim_id', 'insured_id', 'specialty', 'facility_state', 'group_plan_id', 'mindos', \n",
    "                          'claim_line_id', 'cdt_code', 'cpt_code_classification', 'lb_cdt_code', \n",
    "                          'lb_cpt_code_classification', 'lb_specialty'\n",
    "                          \n",
    "                         ])\n",
    "for c in columnsToDrop:\n",
    "    collist.remove(c)\n",
    "datasetFiltered = dataset[collist]\n",
    "\n",
    "# Dataset shape\n",
    "print(datasetFiltered.shape)\n",
    "\n",
    "# Find columns with any missing values\n",
    "columnsDF = pd.DataFrame(datasetFiltered.isnull().any(), columns = np.array(['hasMissing']))\n",
    "print(columnsDF.query('hasMissing == True'))\n",
    "\n",
    "# Find rows with any missing values\n",
    "null_data = datasetFiltered[datasetFiltered.isnull().any(axis=1)]\n",
    "print(null_data.shape[0])\n",
    "\n",
    "# Ignore those rows with missing data\n",
    "datasetFiltered = datasetFiltered.dropna()\n",
    "\n",
    "# Extract the target variable and checking the class distribution\n",
    "target = datasetFiltered['target']\n",
    "datasetFiltered = datasetFiltered.drop('target', 1)\n",
    "print(Counter(target))\n",
    "\n",
    "# Extract the provider_id and DOS variables for future split\n",
    "provider_id = datasetFiltered['provider_id']\n",
    "datasetFiltered = datasetFiltered.drop('provider_id', 1)\n",
    "maxdos = datasetFiltered['maxdos']\n",
    "datasetFiltered = datasetFiltered.drop('maxdos', 1)\n",
    "\n",
    "# Descriptive stats\n",
    "pd.DataFrame(datasetFiltered.describe()).to_csv('descriptive_stats.csv')\n",
    "\n",
    "# Skew for each attribute \n",
    "pd.DataFrame(datasetFiltered.skew()).to_csv('skew.csv')\n",
    "\n",
    "# Correlations\n",
    "pd.DataFrame(datasetFiltered.corr(method='pearson')).to_csv('correlations.csv')\n",
    "\n",
    "# Are there constant variables?\n",
    "constant = datasetFiltered.loc[:, datasetFiltered.apply(pd.Series.nunique) == 1]\n",
    "print(constant.columns)\n",
    "\n",
    "# Checking some variable importance\n",
    "selector = SelectKBest(score_func=f_classif, k=10)\n",
    "fit = selector.fit(datasetFiltered, target)\n",
    "\n",
    "varImp = dict()\n",
    "for variable, score, topX in zip(datasetFiltered.columns, fit.scores_, selector.get_support()):\n",
    "    varImp[variable] = score\n",
    "pd.DataFrame.from_dict(varImp, orient='index').to_csv('varImp.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13097, 112)\n",
      "Index(['avgclaimspermemberprovider', 'avgclaimlineperclaimprovider',\n",
      "       'member_age_time_of_service', 'provider_age_time_of_service',\n",
      "       'amount_paid', 'has_primary_tooth', 'min_total_comb1',\n",
      "       'min_zscore_comb4', '120', '140', '1203', '230', '250', 'PERIODONTICS',\n",
      "       '274', '2140', '290', '330', 'OTHER NON-DENTAL', '240', '272', '3240',\n",
      "       '260', '350', '3120', '4211', 'DIAGNOSTIC', '1208'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "######################################################################################################\n",
    "#Feature selecion\n",
    "#####################################################################################################\n",
    "\n",
    "# Drop some correlated variables (manual analysis - greater than 0.6)\n",
    "collist = datasetFiltered.columns.tolist()\n",
    "columnsHighCorr_GT06 = np.array(['has_radiography','4355','is_member_under_10','9230','amount_claim','0230','amount_cost',\n",
    "                                 '2391','2933','PREVENTIVE','has_bitewing','2392','1120','7140','8220', '9310',\n",
    "                                 'has_stainless_steel_crowns','2930','ADJ','0272','has_pulpotomies','3220','1351',\n",
    "                                 'has_molar','RESTORATIVE', '3330', 'avgticketpermemberprovider', 'avgticketperclaimmember', \n",
    "                                 'avgticketperprovidermember', 'qtdmemberprovider', 'qtdclaimsmember', 'qtdclaimsprovider', \n",
    "                                 'avgclaimsperprovidermember',\n",
    "                                 'avg_total_comb1', 'max_total_comb1', 'avg_zscore_comb1', 'min_zscore_comb1', \n",
    "                                 'max_zscore_comb1', 'avg_total_comb2', 'avg_zscore_comb2', 'max_zscore_comb2', \n",
    "                                 'avg_zscore_comb3', 'max_zscore_comb3', 'avg_zscore_comb4', 'max_zscore_comb4',\n",
    "                                 'sum_total_comb1351', 'avg_total_comb1351', 'min_total_comb1351', 'max_total_comb1351', \n",
    "                                 'sum_total_comb0272','avg_total_comb0272', 'min_total_comb0272', 'max_total_comb0272',\n",
    "                                 'sum_total_comb2', 'max_total_comb2', 'sum_total_comb3', 'avg_total_comb3', \n",
    "                                 'max_total_comb3','sum_total_comb4', 'avg_total_comb4', 'max_total_comb4',\n",
    "                                 'sum_total_comb3220', 'avg_total_comb3220', 'max_total_comb3220', 'indicator_6_eligible',\n",
    "                                 'indicator_8_eligible', 'indicator_9_eligible', 'indicator_13_eligible', \n",
    "                                 'indicator_14_eligible', 'indicator_16_eligible', 'indicator_9_result', \n",
    "                                 'indicator_17_result', 'min_total_comb2', 'min_zscore_comb2', 'min_total_comb3',\n",
    "                                 'min_total_comb4', 'min_zscore_comb3', 'min_ratio_1351', 'max_ratio_1351', 'min_ratio_3220',\n",
    "                                 'max_ratio_3220', 'min_ratio_0272', 'max_ratio_0272', 'indicator_7_eligible', \n",
    "                                 'indicator_10_eligible', 'avg_total_combrest', 'min_total_combrest', 'max_total_combrest',\n",
    "                                 'min_ratio_rest', 'max_ratio_rest', 'sum_total_comb1', 'avgclaimlineperclaimmember',\n",
    "                                 'indicator_17_eligible', 'FQHC', '5120', '0260', 'source', '8080', 'indicator_2_eligible', \n",
    "                                 'indicator_11_eligible', 'indicator_12_eligible', 'min_total_comb3220',\n",
    "                                 'sum_total_combrest', 'avg_ratio_1351', 'avg_ratio_3220', 'avg_ratio_0272', \n",
    "                                 'avg_ratio_rest'\n",
    "                                \n",
    "                                ])\n",
    "\n",
    "for c in columnsHighCorr_GT06:\n",
    "    if c in collist:\n",
    "        collist.remove(c)\n",
    "datasetWithoutCorr = datasetFiltered[collist]\n",
    "\n",
    "# Drop some variables with low importance (p-value < 0.05)\n",
    "filtered_dict = {k:v for (k,v) in varImp.items() if v < 0.05}\n",
    "columnsLowImp = list(filtered_dict.keys())\n",
    "\n",
    "collist = datasetWithoutCorr.columns.tolist()\n",
    "for c in columnsLowImp:\n",
    "    if c in collist:\n",
    "        collist.remove(c)\n",
    "datasetHighImp = datasetWithoutCorr[collist]\n",
    "\n",
    "# Dataset dim\n",
    "print(datasetHighImp.shape)\n",
    "\n",
    "# New correlations\n",
    "pd.DataFrame(datasetHighImp.corr(method='pearson')).to_csv('correlations.csv')\n",
    "\n",
    "# Checking some variable importance\n",
    "selector = SelectKBest(score_func=f_classif, k=28)\n",
    "fit = selector.fit(datasetHighImp, target)\n",
    "\n",
    "varImp = dict()\n",
    "for variable, score, topX in zip(datasetHighImp.columns, fit.scores_, selector.get_support()):\n",
    "    varImp[variable] = score\n",
    "pd.DataFrame.from_dict(varImp, orient='index').to_csv('varImp.csv')\n",
    "\n",
    "# Show the top N most important features\n",
    "kbest = datasetHighImp.ix[0:10:,selector.get_support()]\n",
    "print(kbest.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GD',\n",
       " '2390',\n",
       " '7111',\n",
       " 'PEDO',\n",
       " '4341',\n",
       " '1515',\n",
       " '7510',\n",
       " 'min_total_comb3220',\n",
       " '5820',\n",
       " 'has_ob_ol_surface',\n",
       " '7310',\n",
       " '3221',\n",
       " 'indicator_11_eligible',\n",
       " '2751',\n",
       " '1201',\n",
       " 'indicator_6_result',\n",
       " '1555',\n",
       " '2393']"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columnsLowImp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "######################################################################################################\n",
    "# Some \"global\" parameters\n",
    "#####################################################################################################\n",
    "seed = 7\n",
    "scoring = 'precision'\n",
    "test_size = 0.25\n",
    "n_splits = 10\n",
    "kfold = KFold(n_splits=n_splits, random_state=seed) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "######################################################################################################\n",
    "# Random split\n",
    "#####################################################################################################\n",
    "\n",
    "# Prepare the dataset\n",
    "X = datasetHighImp.values\n",
    "Y = target\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "######################################################################################################\n",
    "# Provider split\n",
    "#####################################################################################################\n",
    "\n",
    "# Append provider_id + target to the dataset\n",
    "datasetSplit = pd.concat([datasetHighImp, provider_id, target], axis=1)\n",
    "\n",
    "# Split by provider_id\n",
    "N = provider_id.size\n",
    "sampleDesiredSize = N * test_size\n",
    "uniqueProviders = list(provider_id.unique())\n",
    "dictProviders = Counter(provider_id)\n",
    "testSample = pd.DataFrame()\n",
    "\n",
    "sampleSize = 0\n",
    "while (sampleSize < sampleDesiredSize):\n",
    "    #chose a random provider\n",
    "    p = random.choice(uniqueProviders)\n",
    "    #avoid duplicated observations\n",
    "    uniqueProviders.remove(p)\n",
    "    #select observations\n",
    "    pSample = datasetSplit[datasetSplit['provider_id'] == p]\n",
    "    #update the final sample\n",
    "    if (sampleSize == 0):\n",
    "        testSample = pSample.copy()\n",
    "    else:\n",
    "        testSample = testSample.append(pSample, ignore_index=True)\n",
    "    #update the sample size\n",
    "    sampleSize = sampleSize + dictProviders[p]\n",
    "\n",
    "# Filter the train sample\n",
    "testProviders = testSample.provider_id.unique()\n",
    "trainSample = datasetSplit[~datasetSplit['provider_id'].isin(testProviders)]\n",
    "\n",
    "# Remove support columns\n",
    "del trainSample['provider_id']\n",
    "del testSample['provider_id']\n",
    "\n",
    "# Prepare the train dataset\n",
    "Y_train = trainSample.target\n",
    "del trainSample['target']\n",
    "X_train = trainSample.values\n",
    "\n",
    "# Prepare the test dataset\n",
    "Y_test = testSample.target\n",
    "del testSample['target']\n",
    "X_test = testSample.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "######################################################################################################\n",
    "# Date split\n",
    "#####################################################################################################\n",
    "\n",
    "# Append provider_id + target to the dataset\n",
    "DOS = pd.to_datetime(maxdos, format='%Y-%m-%d')\n",
    "datasetSplit = pd.concat([datasetHighImp, DOS, target], axis=1)\n",
    "\n",
    "# Split by date\n",
    "N = DOS.size\n",
    "sampleDesiredSize = N * test_size\n",
    "dictDates = Counter(DOS)\n",
    "testSample = pd.DataFrame()\n",
    "\n",
    "sampleSize = 0\n",
    "\n",
    "# Verify the last eligible date to get the sample size\n",
    "dataset_dates = dict(datasetSplit.groupby('maxdos').size())\n",
    "it = iter(sorted(dataset_dates.items(), reverse=True))\n",
    "valid = 0\n",
    "while (valid < sampleDesiredSize):\n",
    "    maxDate = next(it)\n",
    "    valid = valid + maxDate[1]\n",
    "\n",
    "#chose a random date\n",
    "d = random.choice((datasetSplit[datasetSplit['maxdos'] <= maxDate[0]])['maxdos'])\n",
    "while (sampleSize < sampleDesiredSize):\n",
    "    #select observations\n",
    "    dSample = datasetSplit[datasetSplit['maxdos'] == d]\n",
    "    #update the final sample\n",
    "    if (sampleSize == 0):\n",
    "        testSample = dSample.copy()\n",
    "    else:\n",
    "        testSample = testSample.append(dSample, ignore_index=True)\n",
    "    #update the sample size\n",
    "    sampleSize = sampleSize + dSample.shape[0]\n",
    "    #next day\n",
    "    d = d + timedelta(days=1)\n",
    "\n",
    "# Filter the train sample\n",
    "testDates = testSample.maxdos.unique()\n",
    "trainSample = datasetSplit[~datasetSplit['maxdos'].isin(testDates)]\n",
    "\n",
    "# Remove support columns\n",
    "del trainSample['maxdos']\n",
    "del testSample['maxdos']\n",
    "\n",
    "# Prepare the train dataset\n",
    "Y_train = trainSample.target\n",
    "del trainSample['target']\n",
    "X_train = trainSample.values\n",
    "\n",
    "# Prepare the test dataset\n",
    "Y_test = testSample.target\n",
    "del testSample['target']\n",
    "X_test = testSample.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "######################################################################################################\n",
    "# Date split 90/10\n",
    "#####################################################################################################\n",
    "\n",
    "# Append provider_id + target to the dataset\n",
    "DOS = pd.to_datetime(maxdos, format='%Y-%m-%d')\n",
    "datasetSplit = pd.concat([datasetHighImp, DOS, target], axis=1)\n",
    "\n",
    "# Split by date\n",
    "N = DOS.size\n",
    "sampleDesiredSize = N * test_size\n",
    "testSample = pd.DataFrame()\n",
    "\n",
    "# Verify the last eligible date to filter the sample\n",
    "dataset_dates = dict(datasetSplit.groupby('maxdos').size())\n",
    "it = iter(sorted(dataset_dates.items(), reverse=True))\n",
    "valid = 0\n",
    "while (valid < sampleDesiredSize):\n",
    "    maxDate = next(it)\n",
    "    valid = valid + maxDate[1]\n",
    "\n",
    "# Filter datasets\n",
    "testSample = datasetSplit[datasetSplit['maxdos'] >= maxDate[0]]\n",
    "trainSample = datasetSplit[datasetSplit['maxdos'] < maxDate[0]]\n",
    "\n",
    "# Remove support columns\n",
    "del trainSample['maxdos']\n",
    "del testSample['maxdos']\n",
    "\n",
    "# Prepare the train dataset\n",
    "Y_train = trainSample.target\n",
    "del trainSample['target']\n",
    "X_train = trainSample.values\n",
    "\n",
    "# Prepare the test dataset\n",
    "Y_test = testSample.target\n",
    "del testSample['target']\n",
    "X_test = testSample.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADA: 0.678765 (0.029405)\n",
      "GB: 0.729727 (0.015763)\n",
      "RF: 0.752819 (0.013526)\n",
      "CART: 0.790444 (0.015122)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgkAAAF9CAYAAACOOfuyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x289d18e2f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# prepare models \n",
    "models = [] \n",
    "models.append(('ADA', AdaBoostClassifier())) \n",
    "models.append(('GB', GradientBoostingClassifier())) \n",
    "models.append(('RF', RandomForestClassifier())) \n",
    "models.append(('CART', DecisionTreeClassifier())) \n",
    "#models.append(('SVM', SVC()))\n",
    "\n",
    "# evaluate each model in turn \n",
    "results = [] \n",
    "names = [] \n",
    "\n",
    "for name, model in models: \n",
    "    # Create pipeline\n",
    "    estimators = []\n",
    "#    estimators.append(('select_best', SelectKBest(k=28)))\n",
    "    estimators.append(('model', model))\n",
    "    pipeline = Pipeline(estimators)\n",
    "    cv_results = cross_val_score(pipeline, X_train, Y_train, cv=kfold, scoring=scoring) \n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std()) \n",
    "    print(msg)\n",
    "\n",
    "# Compare models\n",
    "fig = pyplot.figure() \n",
    "fig.suptitle('Algorithm Comparison') \n",
    "ax = fig.add_subplot(111) \n",
    "pyplot.boxplot(results) \n",
    "ax.set_xticklabels(names) \n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1569  295]\n",
      " [ 260 1151]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.84      0.85      1864\n",
      "          1       0.80      0.82      0.81      1411\n",
      "\n",
      "avg / total       0.83      0.83      0.83      3275\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the baseline model (the best one from model comparison task)\n",
    "\n",
    "# Create pipeline\n",
    "estimators = []\n",
    "#estimators.append(('select_best', SelectKBest(k=28)))\n",
    "estimators.append(('model', DecisionTreeClassifier(random_state = seed)))\n",
    "baseline = Pipeline(estimators)\n",
    "baseline.fit(X_train, Y_train)\n",
    "#we can change param values -> baseline.set_params(select_best__k=8)\n",
    "\n",
    "# Feature importance\n",
    "#selector = baseline.named_steps['select_best']\n",
    "#selectedFeatures = datasetHighImp.ix[:,selector.get_support()]\n",
    "#model = baseline.named_steps['model']\n",
    "#featureName = pd.DataFrame(selectedFeatures.columns, columns=['Feature'])\n",
    "#featureImp = pd.DataFrame(model.feature_importances_, columns=['Imp'])\n",
    "#pd.concat([featureName, featureImp], axis=1).to_csv('varImpTree.csv')\n",
    "\n",
    "# Test the best model\n",
    "predictions = baseline.predict(X_test)\n",
    "print(confusion_matrix(Y_test, predictions))\n",
    "print(classification_report(Y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17:18:28\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "print(time.strftime(\"%H:%M:%S\"))\n",
    "# Model tuning for CART\n",
    "model = DecisionTreeClassifier(random_state = seed)\n",
    "\n",
    "# Grid search parameters\n",
    "param_grid = {\n",
    "    'criterion' : [\"gini\", \"entropy\"],\n",
    "    'splitter' :   [\"best\", \"random\"],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'min_samples_split': [0.01, 0.0050, 0.0040, 0.0035, 0.0030],\n",
    "    'min_samples_leaf' : [0.01, 0.0050, 0.0040, 0.0035, 0.0030],\n",
    "    'max_depth': [10,20,25,30,40],\n",
    "    'min_impurity_split' : [0.01, 0.0050, 0.0040, 0.0035, 0.0030],\n",
    "    'class_weight': [{0:.1, 1:.9}, {0:.3, 1:.7}, \"balanced\"],\n",
    "    'presort' : [True, False]\n",
    "}\n",
    "\n",
    "# Execute the grid search\n",
    "CV_model = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\n",
    "CV_model_result = CV_model.fit(X_train, Y_train)\n",
    "\n",
    "# Print results\n",
    "print(\"Best: %f using %s\" % (CV_model_result.best_score_, CV_model_result.best_params_))\n",
    "print(time.strftime(\"%H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save the model to disk \n",
    "filename = 'binary_class_model.sav' \n",
    "dump(baseline, open(filename, 'wb'))\n",
    "\n",
    "# load the model from disk \n",
    "#loaded_model = load(open(filename, 'rb')) \n",
    "#result = loaded_model.score(X_test, Y_test) \n",
    "#print(result)# Create the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
