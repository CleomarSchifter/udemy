{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from pickle import dump, load\n",
    "import bisect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23, 5)\n",
      "(23, 5)\n"
     ]
    }
   ],
   "source": [
    "######################################################################################################\n",
    "# Carrega os datasets de treino e teste\n",
    "#####################################################################################################\n",
    "\n",
    "datasetTrainHA = pd.read_csv('datasetTrainHA.csv', low_memory=False)\n",
    "print(datasetTrainHA.shape)\n",
    "\n",
    "datasetTestHA = pd.read_csv('datasetTestHA.csv', low_memory=False)\n",
    "print(datasetTestHA.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "######################################################################################################\n",
    "# Cria o encoder, aplica nos dados de treino e salva para utilizacao nos dados de teste\n",
    "#####################################################################################################\n",
    "\n",
    "###\n",
    "### PARTE 1 - CRIA UMA VARIAVEL NUMERICA (FACTOR) - PODERIAMOS PULAR ESTA ETAPA SE A VARIAVEL QUE \n",
    "### SOFRERA A TRANSFORMACAO ONE-HOT-ENCODER JA FOSSE NUMERICA\n",
    "###\n",
    "\n",
    "# Cria um LabelEncoder para transformar os valores da coluna \"classificacao\" em numeros (factor)\n",
    "le_classificacao = preprocessing.LabelEncoder()\n",
    "le_classificacao.fit(datasetTrainHA.classificacao)\n",
    "\n",
    "# Adiciona <unknown> a lista de valores do Encoder\n",
    "le_classificacao_classes = le_classificacao.classes_.tolist()\n",
    "bisect.insort_left(le_classificacao_classes, '<unknown>')\n",
    "le_classificacao.classes_ = le_classificacao_classes\n",
    "\n",
    "# Cria a coluna numerica no dataset\n",
    "datasetTrainHA['le_classificacao'] = le_classificacao.transform(datasetTrainHA.classificacao)\n",
    "\n",
    "# Salva o Encoder para uso futuro nos dados de teste\n",
    "dump(le_classificacao, open('le_classificacao.sav', 'wb'))\n",
    "\n",
    "###\n",
    "### PARTE 2 - CRIA AS VARIAVEIS DUMMIES\n",
    "###\n",
    "\n",
    "# Cria um novo dataset com a chave + variavel de entrada para a transformacao\n",
    "dataset_new = datasetTrainHA[['chave', 'le_classificacao']]\n",
    "\n",
    "# Cria o OneHotEncoder\n",
    "encoder = OneHotEncoder(categorical_features = np.array([False, True]), dtype=bool, sparse=True)\n",
    "encoder.fit(dataset_new)\n",
    "\n",
    "# Salva o Encoder para uso futuro nos dados de teste\n",
    "dump(encoder, open('encoder.sav', 'wb'))\n",
    "\n",
    "# Prepara o nome das colunas do novo dataset\n",
    "colnames = list(le_classificacao.classes_)\n",
    "index = colnames.index('<unknown>')\n",
    "del colnames[index]\n",
    "colnames.append('chave')\n",
    "\n",
    "# Exemplo se existisse mais de uma coluna para fazer a trasformacao\n",
    "#colnames = list(le_classificacao.classes_)\n",
    "#index = colnames.index('<unknown>')\n",
    "#del colnames[index]\n",
    "#colnamesClass2 = list(le_classificacao2.classes_)\n",
    "#for c in colnamesClass2:\n",
    "#    if c != '<unknown>':\n",
    "#        colnames.append(c)\n",
    "#colnames.append('chave')\n",
    "\n",
    "# Executa a transformacao nos dados de treino\n",
    "results = encoder.transform(dataset_new)\n",
    "dataset_encode = pd.DataFrame(results.toarray(), columns=colnames)\n",
    "\n",
    "# Junta os dados no dataset final\n",
    "dataset_merge = pd.merge(datasetTrainHA, dataset_encode, on='chave', how='inner')\n",
    "\n",
    "# Exporta o dataset de treino\n",
    "dataset_merge.to_csv(\"dataset_merge.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######################################################################################################\n",
    "# Carrega o encoder e aplica nos dados de treino\n",
    "#####################################################################################################\n",
    "\n",
    "# Carrega o Label Encoder\n",
    "le_classificacao = load(open('le_classificacao.sav', 'rb')) \n",
    "\n",
    "# Atualiza os valores da coluna \"classificacao\" do dataset de treino para <unknown> os valores que \n",
    "# nao pertencem as classes do Label Encoder\n",
    "datasetTestHA.loc[ ~datasetTestHA['classificacao'].isin(le_classificacao.classes_), 'classificacao' ] = '<unknown>'\n",
    "\n",
    "# Aplica o Label Encoder ao dataset de treino\n",
    "datasetTestHA['le_classificacao'] = le_classificacao.transform(datasetTestHA.classificacao)\n",
    "\n",
    "# Cria um novo dataset com a chave + variavel de entrada para a transformacao\n",
    "dataset_new = datasetTestHA[['chave', 'le_classificacao']]\n",
    "\n",
    "# Carrega o OneHotEncoder\n",
    "encoder = load(open('encoder.sav', 'rb')) \n",
    "\n",
    "# Prepara o nome das colunas do novo dataset\n",
    "colnames = list(le_classificacao.classes_)\n",
    "index = colnames.index('<unknown>')\n",
    "del colnames[index]\n",
    "colnames.append('chave')\n",
    "\n",
    "# Executa a transformacao nos dados de teste\n",
    "results = encoder.transform(dataset_new)\n",
    "dataset_encode = pd.DataFrame(results.toarray(), columns=colnames)\n",
    "\n",
    "# Merging datasets\n",
    "dataset_merge = pd.merge(datasetTestHA, dataset_encode, on='chave', how='inner')\n",
    "\n",
    "# Exporta o dataset de treino\n",
    "dataset_merge.to_csv(\"dataset_merge.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {
   "environment": null,
   "summary": "One Hot Encoding",
   "url": "https://anaconda.org/weslleymoura/onehotencoderha"
  },
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
